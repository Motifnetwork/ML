{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T09:50:35.904151Z",
     "start_time": "2023-07-03T09:50:35.834329Z"
    }
   },
   "outputs": [],
   "source": [
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "_transport = RequestsHTTPTransport(\n",
    "    url=url1,\n",
    "    use_json=True,\n",
    ")\n",
    "\n",
    "client = Client(\n",
    "    transport=_transport,\n",
    "    fetch_schema_from_transport=True,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "from urllib3.exceptions import IncompleteRead\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T21:15:31.518655Z",
     "start_time": "2023-07-02T20:42:14.855045Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [33:16<00:00, 10.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterate over eras from 1 to 1125\n",
    "for era_id in tqdm(range(1, 1126)):\n",
    "    # Construct the query for the current era\n",
    "    query = '''\n",
    "    query MyQuery {\n",
    "      eraNominations(where: {era: {id_eq: \"%d\"}}) {\n",
    "        nominatorId\n",
    "        validator {\n",
    "          nominatorsCount\n",
    "          selfBonded\n",
    "          totalBonded\n",
    "          validatorId\n",
    "        }\n",
    "        id\n",
    "        amount\n",
    "      }\n",
    "    }\n",
    "    ''' % era_id\n",
    "\n",
    "    # Retry loop for handling incomplete reads\n",
    "    retries = 20\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            # Execute the query and get the result\n",
    "            result = client.execute(gql(query))\n",
    "            break\n",
    "        except IncompleteRead as e:\n",
    "            print(f\"IncompleteRead error occurred, retrying... {retries} retries left\")\n",
    "            retries -= 1\n",
    "            time.sleep(10)\n",
    "\n",
    "    # Check if the result contains the 'eraNominations' key\n",
    "    if 'eraNominations' in result:\n",
    "        era_nominations = result['eraNominations']\n",
    "\n",
    "        # Convert the nominations data to a DataFrame\n",
    "        era_df = pd.DataFrame(era_nominations)\n",
    "\n",
    "        # Split the 'validator' column into separate columns\n",
    "        validator_df = era_df['validator'].apply(pd.Series)\n",
    "        era_df = pd.concat([era_df.drop(['validator'], axis=1), validator_df], axis=1)\n",
    "\n",
    "        # Add the era_id column to the DataFrame\n",
    "        era_df['era_id'] = era_id\n",
    "\n",
    "        # Concatenate the current era DataFrame with the main DataFrame\n",
    "        df = pd.concat([df, era_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T21:23:20.038087Z",
     "start_time": "2023-07-02T21:21:58.962358Z"
    }
   },
   "outputs": [],
   "source": [
    "# final_df.to_csv('nominator_data_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_pickle('nominator_data_full.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T21:19:52.751641Z",
     "start_time": "2023-07-02T21:19:52.673981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.era_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T21:20:20.364844Z",
     "start_time": "2023-07-02T21:20:19.481987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.validatorId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T21:20:39.193727Z",
     "start_time": "2023-07-02T21:20:37.136734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80709"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nominatorId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T21:25:15.270845Z",
     "start_time": "2023-07-02T21:25:15.266699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19157515"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# Load data\n",
    "#df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# For the purpose of example, I'll create a random dataframe.\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame({\n",
    "    'nominatorId': np.random.choice(range(80709), 1000),\n",
    "    'validatorId': np.random.choice(range(1185), 1000),\n",
    "    'totalBonded': np.random.rand(1000),\n",
    "})\n",
    "\n",
    "# Create a pivot table\n",
    "pivot_table = df.pivot_table(values='totalBonded', index='nominatorId', columns='validatorId')\n",
    "\n",
    "@interact\n",
    "def plot_heatmap(topk=IntSlider(min=1, max=50, value=10)):\n",
    "    # Select top k nominators and validators\n",
    "    top_nominators = pivot_table.sum(axis=1).nlargest(topk).index\n",
    "    top_validators = pivot_table.sum(axis=0).nlargest(topk).index\n",
    "\n",
    "    # Select corresponding rows and columns from pivot table\n",
    "    subset = pivot_table.loc[top_nominators, top_validators]\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(subset, cmap='viridis')\n",
    "    plt.title(f\"Heatmap for Top {topk} Validators and Nominators\")\n",
    "    plt.xlabel(\"Validators\")\n",
    "    plt.ylabel(\"Nominators\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T09:23:53.389714Z",
     "start_time": "2023-07-03T09:23:53.385746Z"
    }
   },
   "outputs": [],
   "source": [
    "df_agg = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a list of labels (nominatorId and validatorId)\n",
    "labels = list(df_agg['nominatorId'].unique()) + list(df_agg['validatorId'].unique())\n",
    "\n",
    "# Create a list of colors for the labels, here for simplicity, nominators are colored blue and validators red\n",
    "colors = ['blue'] * len(df_agg['nominatorId'].unique()) + ['red'] * len(df_agg['validatorId'].unique())\n",
    "\n",
    "# Create a dictionary mapping for the labels\n",
    "label_dict = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Prepare source, target and value lists\n",
    "source = df_agg['nominatorId'].map(label_dict)\n",
    "target = df_agg['validatorId'].map(label_dict)\n",
    "value = df_agg['amount']\n",
    "\n",
    "# Create a Sankey diagram\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color='black', width=0.5),\n",
    "        label=labels,\n",
    "        color=colors\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=source,  # indices correspond to labels\n",
    "        target=target,  # indices correspond to labels\n",
    "        value=value\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(title_text='Flow of Amounts from Nominators to Validators', font_size=10)\n",
    "fig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import imageio\n",
    "\n",
    "# Preprocess the data: normalize 'amount' for each era\n",
    "df['normalized_amount'] = df.groupby('era_id')['amount'].apply(lambda x: x / x.max())\n",
    "\n",
    "# Get the list of eras\n",
    "eras = df['era_id'].unique()\n",
    "\n",
    "# Create a directory for storing images if not exists\n",
    "import os\n",
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "\n",
    "# Create and save a heatmap for each era\n",
    "for era in eras:\n",
    "    # Get the data for the era\n",
    "    df_era = df[df['era_id'] == era]\n",
    "\n",
    "    # Create a pivot table\n",
    "    pivot_table = df_era.pivot_table(values='normalized_amount', index='nominatorId', columns='validatorId', fill_value=0)\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(pivot_table, cmap='viridis')\n",
    "    plt.title(f\"Era {era}\")\n",
    "\n",
    "    # Save the heatmap as an image\n",
    "    plt.savefig(f'images/heatmap_{era}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Create a video from images\n",
    "images = [imageio.imread(f'images/heatmap_{era}.png') for era in eras]\n",
    "imageio.mimsave('heatmap_video.gif', images, fps=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
